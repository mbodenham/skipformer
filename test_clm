#!/bin/bash
export OMP_NUM_THREADS=8
NGPUS=$(nvidia-smi --list-gpus | wc -l)
NGPUS=1

MODEL=$1
BS=16

#WikiText-103
python -m torch.distributed.launch \
          --nproc_per_node=$NGPUS run_clm.py \
          --model_name_or_path logs/language-modeling/openwebtext/$MODEL \
          --output_dir logs/language-modeling/wikitext-103/$MODEL \
          --cache_dir data \
          --per_device_eval_batch_size $BS \
          --preprocessing_num_workers 64 \
          --do_eval \
          --dataset_name wikitext \
          --dataset_config_name wikitext-103-raw-v1
if [ $? -ne 0 ]
then
  exit 1
fi

# #Billion Word
python -m torch.distributed.launch \
          --nproc_per_node=$NGPUS run_clm.py \
          --model_name_or_path logs/language-modeling/openwebtext/$MODEL \
          --output_dir logs/language-modeling/lm1b/$MODEL \
          --cache_dir data \
          --per_device_eval_batch_size $BS \
          --preprocessing_num_workers 64 \
          --do_eval \
          --dataset_name lm1b
if [ $? -ne 0 ]
then
  exit 1
fi

# #Penn Treebank
python -m torch.distributed.launch \
          --nproc_per_node=$NGPUS run_clm.py \
          --model_name_or_path logs/language-modeling/openwebtext/$MODEL \
          --output_dir logs/language-modeling/ptb/$MODEL \
          --cache_dir data \
          --per_device_eval_batch_size $BS \
          --preprocessing_num_workers 64 \
          --do_eval \
          --dataset_name ptb_text_only
if [ $? -ne 0 ]
then
  exit 1
fi

# #enwik8
python -m torch.distributed.launch \
          --nproc_per_node=$NGPUS run_clm.py \
          --model_name_or_path logs/language-modeling/openwebtext/$MODEL \
          --output_dir logs/language-modeling/enwiki8/$MODEL \
          --cache_dir data \
          --per_device_eval_batch_size $BS \
          --preprocessing_num_workers 64 \
          --do_eval \
          --dataset_name enwik8 \
          --dataset_config_name enwik8
if [ $? -ne 0 ]
then
  exit 1
fi

# #OpenWebText
python -m torch.distributed.launch \
          --nproc_per_node=$NGPUS run_clm.py \
          --model_name_or_path logs/language-modeling/openwebtext/$MODEL \
          --output_dir logs/language-modeling/openwebtext/$MODEL \
          --cache_dir data \
          --per_device_eval_batch_size $BS \
          --preprocessing_num_workers 64 \
          --do_eval \
          --dataset_name Skylion007/openwebtext \
          --dataset_config_name plain_text
if [ $? -ne 0 ]
then
  exit 1
fi
